{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predict_health_costs_with_regression.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satvik-creatifying/Health-Cost-Predictor/blob/main/Predict_health_costs_with_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9TX15KOkPBV"
      },
      "source": [
        "In this we will predict healthcare costs using a regression algorithm.\n",
        "\n",
        "We are given a dataset that contains information about different people including their healthcare costs. Use the data to predict healthcare costs based on new data.\n",
        "\n",
        "The first two cells of this notebook import libraries and the data.\n",
        "\n",
        "Used 80% of the data as the `train_dataset` and 20% of the data as the `test_dataset`.\n",
        "\n",
        "`pop` off the \"expenses\" column from these datasets to create new datasets called `train_labels` and `test_labels`. \n",
        "\n",
        "Created a model and trained it with the `train_dataset`. Run the final cell in this notebook to check your model. The final cell will use the unseen `test_dataset` to check how well the model generalizes.\n",
        "\n",
        "The final cell will also predict expenses using the `test_dataset` and graph the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rRo8oNqZ-Rj"
      },
      "source": [
        "!wget -N https://cdn.freecodecamp.org/project-data/health-costs/insurance.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/tensorflow/docs"
      ],
      "metadata": {
        "id": "1EXOoFgL9VlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiX2FI4gZtTt"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcopvQh3X-kX"
      },
      "source": [
        "dataset = pd.read_csv('insurance.csv')\n",
        "len(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "id": "zxiMgJl713Qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = dataset\n",
        "df[\"sex\"] = pd.factorize(df[\"sex\"])[0]\n",
        "df[\"region\"] = pd.factorize(df[\"region\"])[0]\n",
        "df[\"smoker\"] = pd.factorize(df[\"smoker\"])[0]\n",
        "dataset = df\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "1swchqpC182q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = dataset.sample(frac=0.2)\n",
        "len(test_dataset)"
      ],
      "metadata": {
        "id": "GTv_b_2F2alR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = dataset[~dataset.isin(test_dataset)].dropna()\n",
        "len(train_dataset)"
      ],
      "metadata": {
        "id": "VTeMe6fe2d6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.head()"
      ],
      "metadata": {
        "id": "3a1OaAv42hmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = train_dataset.pop(\"expenses\")\n",
        "train_labels.head()"
      ],
      "metadata": {
        "id": "eGVdIzkdArmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.head()"
      ],
      "metadata": {
        "id": "mYwB6SxY2neJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels = test_dataset.pop(\"expenses\")\n",
        "test_labels.head()"
      ],
      "metadata": {
        "id": "tjoshZZH20tP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset.head()"
      ],
      "metadata": {
        "id": "jD7500dC24lw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalizer = layers.experimental.preprocessing.Normalization()\n",
        "normalizer.adapt(np.array(train_dataset))\n",
        "\n",
        "model = keras.Sequential([\n",
        "    normalizer,\n",
        "    layers.Dense(16),\n",
        "    layers.Dense(4),\n",
        "    layers.Dropout(.2),\n",
        "    layers.Dense(1),\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.optimizers.Adam(learning_rate=0.1),\n",
        "    loss='mae',\n",
        "    metrics=['mae', 'mse']\n",
        ")\n",
        "model.build()\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "id": "N57rIR6B4mFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    train_labels,\n",
        "    epochs=200,\n",
        "    validation_split=0.5,\n",
        "    verbose=0, # disable logging\n",
        ")\n",
        "\n",
        "print(history)"
      ],
      "metadata": {
        "id": "ncH3_gbMA72R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RUN THIS CELL TO TEST YOUR MODEL. DO NOT MODIFY CONTENTS.\n",
        "# Test model by checking how well the model generalizes using the test set.\n",
        "loss, mae, mse = model.evaluate(test_dataset, test_labels, verbose=2)\n",
        "\n",
        "print(\"Testing set Mean Abs Error: {:5.2f} expenses\".format(mae))\n",
        "\n",
        "if mae < 3500:\n",
        "  print(\"You passed the challenge. Great job!\")\n",
        "else:\n",
        "  print(\"The Mean Abs Error must be less than 3500. Keep trying.\")\n",
        "\n",
        "# Plot predictions.\n",
        "test_predictions = model.predict(test_dataset).flatten()\n",
        "\n",
        "a = plt.axes(aspect='equal')\n",
        "plt.scatter(test_labels, test_predictions)\n",
        "plt.xlabel('True values (expenses)')\n",
        "plt.ylabel('Predictions (expenses)')\n",
        "lims = [0, 50000]\n",
        "plt.xlim(lims)\n",
        "plt.ylim(lims)\n",
        "_ = plt.plot(lims,lims)"
      ],
      "metadata": {
        "id": "fK8Wfc2cBDeP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
